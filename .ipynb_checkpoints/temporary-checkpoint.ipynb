{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "import json\n",
    "import numpy as np\n",
    "impot regex as re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%run config.ipynb # this line runs the config.ipynb file, which stores my API key\n",
    "\n",
    "# import researchpy as rp\n",
    "# import scipy.stats as stats  # these 2 not needed currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting display options for printing pandas dfs\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_colwidth', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0775cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating functions to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0678a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=\",\".join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response[\"items\"]: # the key 'items' in the response JSON dict gives a list of items, each one about a specified YT channel.\n",
    "        data = {\n",
    "            \"channel_name\" : item[\"snippet\"][\"title\"],\n",
    "            \"playlistId\" : item[\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "        }\n",
    "        \n",
    "        all_data.append(data)\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "                    part='contentDetails',\n",
    "                    playlistId = playlist_id,\n",
    "                    maxResults = 50,\n",
    "                    pageToken = next_page_token)\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f58c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):\n",
    "\n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "    \n",
    "    return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81363af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key)\n",
    "\n",
    "channel_ids = [ 'UCa90xqK2odw1KV5wHU9WRhg', 'UCX6OQ3DkcsbYNE6H8uQQuVA', 'UCzQUP1qoWDoEbmsQxvdjxgQ']\n",
    "# these ^ are the channel IDs of The Office, PowerfulJRE and MrBeast. I found them by 'inspecting source'  \n",
    "\n",
    "channel_stats_df = get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d69af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Putting all video details into one df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bffb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "playlist_ids = channel_stats_df[\"playlistId\"].values\n",
    "\n",
    "for playlist_id in playlist_ids:\n",
    "    video_ids = get_video_ids(youtube, playlist_id)\n",
    "    video_details_df = get_video_details(youtube, video_ids)\n",
    "    df_list.append(video_details_df)\n",
    "    \n",
    "all_channels_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_df[\"channelTitle\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55984e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mr Beast Dollar Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ac714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amending data types of columns\n",
    "mr_beast_df[[\"viewCount\",\"likeCount\", 'commentCount']] = mr_beast_df[[\"viewCount\",\"likeCount\", 'commentCount']].apply(pd.to_numeric)\n",
    "mr_beast_df[\"publishedAt\"] = pd.to_datetime(mr_beast_df[\"publishedAt\"], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Adding a new column which is a Boolean denoting whether the title has \"$\" in it or not\n",
    "mr_beast_df[\"title_has_$\"] = mr_beast_df[\"title\"].str.contains(\"\\$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772251ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we reduce the dataset for this analysis down to just the videos after Mr Beast posted his first one with a dollar sign \n",
    "# in it. This is because there's a lot of less-watched vids he made early on that were of a different genre to his later videos\n",
    "# It makes sense to start the analysis from when he began posting videos similar rto what he currently produces.\n",
    "\n",
    "first_dollar_vid = mr_beast_df[mr_beast_df[\"title_has_$\"] == True].sort_values(by='publishedAt').iloc[0][\"publishedAt\"]\n",
    "\n",
    "print(first_dollar_vid)\n",
    "\n",
    "mr_beast_dollars_df = mr_beast_df.copy()\n",
    "mr_beast_dollars_df = mr_beast_dollars_df[mr_beast_dollars_df[\"publishedAt\"] > first_dollar_vid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dollars_df = mr_beast_dollars_df[mr_beast_dollars_df[\"title_has_$\"] == True]\n",
    "no_dollars_df = mr_beast_dollars_df[mr_beast_dollars_df[\"title_has_$\"] == False]\n",
    "\n",
    "# ^ in case we want to look at the df's separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc92e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting some stats from the dollars_df and no_dollars_df\n",
    "\n",
    "print(\"Number of dollars vids: \" + str(len(dollars_df)))\n",
    "print(\"Number of No dollars vids: \" + str(len(no_dollars_df)))\n",
    "\n",
    "print(\"Dollars average: \" + str(dollars_df[\"viewCount\"].mean().round(1)))\n",
    "print(\"No Dollars average: \" + str(no_dollars_df[\"viewCount\"].mean().round(1)))#\n",
    "\n",
    "print(\"Dollars max: \" + str(dollars_df['viewCount'].max()))\n",
    "print(\"No Dollars max: \" + str(no_dollars_df['viewCount'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More in depth stats\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "\n",
    "print(\"DOLLARS:\")\n",
    "print(dollars_df[\"viewCount\"].describe().apply(\"{0:.2f}\".format))\n",
    "print(\"\\nNO DOLLARS:\")\n",
    "print(no_dollars_df[\"viewCount\"].describe().apply(\"{0:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e491455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(df_dict):\n",
    "    \n",
    "    for df_name in df_dict:\n",
    "        df = df_dict[df_name]\n",
    "        df_new = df.copy()\n",
    "        df_new[\"colour\"] = df[\"title_has_$\"].map({True:\"green\", False:\"red\"}) # this line was added in hope that the plots would be made on same graph, but no dic - ATM\n",
    "        ax = df_new.plot(x=\"publishedAt\", y=\"viewCount\", color=df_new[\"colour\"].values, style=\".\", legend=None)\n",
    "        ax.get_yaxis().set_major_formatter(\n",
    "            matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x)/1000000, ',')))\n",
    "        plt.ylabel(\"View count (millions)\")\n",
    "        plt.xlabel(\"Video publish date\")\n",
    "        title = \"Video view counts - '$' NOT in video title\" if \"no\" in df_name else \"Video view counts - '$' in video title\" \n",
    "        plt.title(title)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9cfaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    \"dollars_df\": dollars_df,\n",
    "    \"no_dollars_df\": no_dollars_df\n",
    "    }\n",
    "\n",
    "create_plot(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "After looking at the stats and the plots of the sets of videos uploaded by Mr Beast that either have or do not have the \"$\" symbol in the title, I can see that ones with a dollar sign have a higher view count. The average number of views for videos with dollars is more than double those without (94 million compared to 40 million). The median is also 10x higher whioch is a huge disproprtion. The maximum nubmer of views is far higher as well, however this video along with one other (both around 800 million views mark) are outliers when compared with view counts for other \"dollar\" videos, as can be seen in the time series plots.\n",
    "\n",
    "A potential reason for the difference in view counts here is that the videos with the dollar symbol in the title of Mr Beast's videos usually have a monetary prize that contestants can win (i.e. \"Offering People $100,000 To Quit Their Job\"). The viewers of his videos take more interest in videos of these types than ones that do not have a prize as a focual point of the video.\n",
    "\n",
    "Based on this, if Mr Beast was primarily concerned on maximising the number of views of the videos, I would suggest uploading more videos with the \"$\" in the title. However this could mean he needs to offer the people participating in his videos large amounts of moeny which he may not be keen to do, so I'll leave that decison up to him!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5882095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Relationship between likes, views, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_df[['viewCount', 'likeCount', 'commentCount']] = all_channels_df[['viewCount', 'likeCount', 'commentCount']].apply(pd.to_numeric)\n",
    "all_channels_df[\"likes_to_views\"] = (all_channels_df[\"likeCount\"] / all_channels_df[\"viewCount\"]) *100\n",
    "\n",
    "\n",
    "mr_beast_df = all_channels_df[all_channels_df[\"channelTitle\"] == \"MrBeast\"]\n",
    "jre_df = all_channels_df[all_channels_df[\"channelTitle\"] == \"PowerfulJRE\"]\n",
    "the_office_df = all_channels_df[all_channels_df[\"channelTitle\"] == \"The Office\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jre_df[[\"likes_to_views\",'viewCount', 'likeCount', 'commentCount']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mr_beast_df = mr_beast_df.sort_values(\"viewCount\", ascending=False)\n",
    "# jre_df = jre_df.sort_values(\"viewCount\", ascending=False)\n",
    "# the_office_df = the_office_df.sort_values(\"viewCount\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing this row as it causes issue where its puts in top row when sorting likes to views as it has 0 views\n",
    "\n",
    "jre_df = jre_df[jre_df[\"title\"] != \"JRE Fight Companion - February 11, 2023\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jre_df_likes_to_views = jre_df.sort_values(\"likes_to_views\", ascending=False).head(10)\n",
    "jre_df_views = jre_df.sort_values(\"viewCount\", ascending=False).head(10)\n",
    "jre_df_likes = jre_df.sort_values(\"likeCount\", ascending=False).head(10)\n",
    "jre_df_comments = jre_df.sort_values(\"commentCount\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the comment likes-to-views ratio of top 10 JRE vids\n",
    "ax = jre_df_likes_to_views.plot.barh(x=\"title\", y=\"likes_to_views\", legend=None)\n",
    "ax.get_xaxis().set_major_formatter(\n",
    "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "ax.set(xlabel=\"Likes to views ratio (percentage)\", ylabel=None, title=\"Top 10 JRE videos by likes-to-views ratio\")\n",
    "\n",
    "\n",
    "# def add_value_label(x_list,y_list):\n",
    "#     for i in range(1, len(x_list)+1):\n",
    "#         plt.text(i,y_list[i-1],y_list[i-1])\n",
    "\n",
    "# add_value_label(jre_df_likes_to_views[\"title\"].values, jre_df_likes_to_views[\"likes_to_views\"])\n",
    "\n",
    "# Plotting the view count of top 10 JRE vids\n",
    "ax = jre_df_views.plot.barh(x=\"title\", y=\"viewCount\", legend=None)\n",
    "ax.get_xaxis().set_major_formatter(\n",
    "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x)/1000000, ',')))\n",
    "ax.set(xlabel=\"View count (millions)\", ylabel=None, title=\"Top 10 viewed JRE videos\")\n",
    "\n",
    "# Plotting the like count of top 10 JRE vids\n",
    "ax = jre_df_likes.plot.barh(x=\"title\", y=\"likeCount\", legend=None)\n",
    "ax.get_xaxis().set_major_formatter(\n",
    "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x)/1000, ',')))\n",
    "ax.set(xlabel=\"Like count (thousands)\", ylabel=None, title=\"Top 10 liked JRE videos\")\n",
    "\n",
    "# Plotting the comment count of top 10 JRE vids\n",
    "ax = jre_df_comments.plot.barh(x=\"title\", y=\"commentCount\", legend=None)\n",
    "ax.get_xaxis().set_major_formatter(\n",
    "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x)/1000, ',')))\n",
    "ax.set(xlabel=\"Comment count (thousands)\", ylabel=None, title=\"Top 10 commented JRE videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jre_df[jre_df[\"title\"].isin([\"Joe Rogan Experience #1169 - Elon Musk\", \"Joe Rogan Experience #1315 - Bob Lazar & Jeremy Corbell\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (610515.0/1050883.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a4440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis on The Office videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Want to look at the relation between length of videos and how many views the get and their like like-to-view ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c900cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_office_df = all_channels_df[all_channels_df[\"channelTitle\"] == \"The Office\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See below markdown for explanation on what I'm doing in this cell.\n",
    "\n",
    "print(len(the_office_df))\n",
    "\n",
    "mask_longer_than_hour = the_office_df[\"duration\"].str.contains(\"H\")\n",
    "# print(mask_longer_than_hour)\n",
    "\n",
    "the_office_df = the_office_df[~mask_longer_than_hour] # note the tilda here!\n",
    "\n",
    "print(len(the_office_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "this shows us how many videos are more than an hour long. Note you should print the head of \n",
    "the_office_df[\"duration\"] col to see the format of duration. Its a bit weird, with H, M and S\n",
    "used to denote hours, mins and secs.\n",
    "\n",
    "From the above code we can see there's only 1 vid with duration more than an hour. This vid is in\n",
    "fact 10hrs long. We remove this video from our analysis as it is a huge outlier compared to \n",
    "other videos and this would distort our plots later on (all the shorter vids would be bunched \n",
    "together in order to display the vid that is 10hrs long.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minutes(wd):\n",
    "    try:\n",
    "        if \"T\" not in wd:\n",
    "            return 0\n",
    "\n",
    "        elif \"S\" not in wd:\n",
    "            return int(wd[2:].split(\"M\")[0])\n",
    "\n",
    "        elif \"M\" not in wd:\n",
    "            secs = int(wd[2:].split(\"S\")[0])\n",
    "            mins = round(secs/60,2)\n",
    "            return mins\n",
    "\n",
    "        else:\n",
    "            nums = re.search('PT(.+?)M(.+?)S', wd)\n",
    "            if nums:\n",
    "                mins = int(nums.group(1))\n",
    "                secs = int(nums.group(2))\n",
    "            return mins + round(secs/60, 2)\n",
    "    except:\n",
    "        print(\"ISSUE WITH THIS VALUE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_minutes(\"PT12M59S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.2f}'.format):\n",
    "    print(the_office_df[[\"duration\", \"duration_time\"]].head())\n",
    "    \n",
    "# NOTE: I printed it like this because the precsion was note close enough in duration_time col\n",
    "# without it and I wanted the vals to be more precise.\n",
    "\n",
    "# Here's what I want to plot:\n",
    "print(\"\\n\")\n",
    "print(the_office_df[[\"duration_time\", \"viewCount\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = the_office_df.plot.scatter(x=\"duration_time\", y=\"viewCount\")\n",
    "\n",
    "# This^ gives an unclear plot as most of the data points are very bunced up. Will remove vids that\n",
    "# are >20mins long.\n",
    "\n",
    "the_office_df = the_office_df[the_office_df[\"duration_time\"] < 20]\n",
    "\n",
    "ax = the_office_df.plot.scatter(x=\"duration_time\", y=\"viewCount\", s=5)\n",
    "ax.get_yaxis().set_major_formatter(\n",
    "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x)/1000000, ',')))\n",
    "ax.set_xlabel(\"Video duration (minutes)\")\n",
    "ax.set_ylabel(\"View count (millions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9768fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(the_office_df[\"duration_time\"].corr(the_office_df[\"viewCount\"]))\n",
    "print(round(the_office_df['duration_time'].mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "From the scatter plot, it doesn't immediately seem like there is much of a relationship between the video duration and view count. \n",
    "The correlation between these 2 variables was calculated to be 0.188 which indicates a slight positive correlation. However, it's not strong enough to suggest increasing the length of videos. The video with the second hifghest nubmer of views at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c788e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(the_office_df.loc[the_office_df[\"viewCount\"] >37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9c20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0392592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9b208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf2a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35e2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173612f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99de563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ce34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df473e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3120e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8ab86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadccfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5759f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc037079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbead92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14aa9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68840d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac48e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a75a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_analysis",
   "language": "python",
   "name": "youtube_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
